{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting with XGBoost for the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import xgboost as xgb \n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all data file\n",
    "with open('all_data.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "# df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns neighbors node names for a given node\n",
    "def get_neighbors(data, n):\n",
    "    t = data[data['node']==n]['neib_node'].values.flatten().tolist()[0]\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns prices list for a give node\n",
    "def get_prices(data, n):\n",
    "    prices_cols = data.columns[4:]\n",
    "    t = data[data['node']==n][prices_cols].values.flatten().tolist()\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecasts and returns RMSE and MAPE for a provided dataframe\n",
    "def forecast_XGBoost(data, forecast_days, lags=[], neighbors=[], neighbors_lag=366):\n",
    "    data = data.copy()\n",
    "    #creating lag columns for poi price and shifting \n",
    "    for i_lag in lags:\n",
    "        data['price_lag_'+str(i_lag)] = data['price'].shift(i_lag)\n",
    "    #creating lag columns for neibghors prices and shifting\n",
    "    for neib in neighbors:\n",
    "        data[neib] = data[neib].shift(neighbors_lag)\n",
    "    # removing NaNs\n",
    "    data.dropna(inplace = True)\n",
    "    # test/train split\n",
    "    train, test = data[:-forecast_days], data[-forecast_days:] \n",
    "    # preparing features list\n",
    "    lags_col_names = ['price_lag_'+str(x) for x in lags] #column names\n",
    "    features = ['day_of_week', 'month', 'year'] + lags_col_names + neighbors\n",
    "    target = 'price'   \n",
    "    # test/train datasets  \n",
    "    X_train, y_train = train [features], train [target]\n",
    "    X_test, y_test = test [features], test [target]\n",
    "    # model\n",
    "    model = xgb.XGBRegressor(booster= 'gbtree', base_score=0.5, max_depth=3, early_stopping_rounds=50)\n",
    "    model = model.fit(X_train, y_train,\n",
    "              eval_set=[(X_train, y_train)],\n",
    "              verbose = False)\n",
    "    yhat = model.predict (X_test)\n",
    "    # accuracy metrix\n",
    "    rmse_res = mse(y_test, yhat, squared=False)\n",
    "    mape_res = mape(y_test, yhat)\n",
    "    \n",
    "    return round(rmse_res, 2), round(mape_res, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Npde: 1006113 --> k:0 --> Success:-527     \r"
     ]
    }
   ],
   "source": [
    "# all data file\n",
    "with open('all_data.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "# settings\n",
    "lags = [366]\n",
    "number_of_neighbors = 1\n",
    "list_of_nodes = df['node'].tolist() #[100419]\n",
    "dates = pd.date_range(start='2019-12-05', periods = 1429)\n",
    "forecast_size=30\n",
    "\n",
    "#resulting dict and aux counters\n",
    "result = {'node':[], 'RMSE_1':[], 'MAPE_1':[], 'RMSE_2':[], 'MAPE_2':[]}\n",
    "balance = 0 # \n",
    "k=len(list_of_nodes)\n",
    "\n",
    "for node in list_of_nodes:\n",
    "    # print(\"working for:\", node)\n",
    "    prices = get_prices(df, node)\n",
    "    curr_df = pd.DataFrame(data = {'data':dates, 'price':prices})\n",
    "    curr_df['day_of_week'] = curr_df['data'].dt.dayofweek\n",
    "    curr_df['month'] = curr_df['data'].dt.month\n",
    "    curr_df['year'] = curr_df['data'].dt.year\n",
    "    # add neighbors\n",
    "    neighbors = get_neighbors(df, node)[:number_of_neighbors]\n",
    "    neighb_to_remove = []\n",
    "    for neighbor in neighbors:\n",
    "        p = get_prices(df, neighbor)\n",
    "        if (len(p) == 1429):\n",
    "            curr_df[neighbor] = p\n",
    "        else: \n",
    "            neighb_to_remove.append(neighbor)\n",
    "    neighbors = list(set(neighbors) - set(neighb_to_remove))\n",
    "    # curr_df.dropna()\n",
    "    \n",
    "#     #forecast w/o poi price lag\n",
    "#     rmse_ret_base, mape_ret_base = forecast_XGBoost (curr_df, forecast_size)\n",
    "#     print(\"RMSE base:\", rmse_ret_base, \"MAPE base:\", mape_ret_base)\n",
    "    \n",
    "    #forecast with poi price lag(s)\n",
    "    rmse_1, mape_1 = forecast_XGBoost (curr_df, forecast_size, lags)\n",
    "    # print(\"RMSE base:\", rmse_1, \"MAPE base:\", mape_1)\n",
    "    \n",
    "    #forecast with poi price lag(s) and neighbors\n",
    "    rmse_2, mape_2 = forecast_XGBoost (curr_df, forecast_size, lags, neighbors = neighbors)\n",
    "    # print(\"RMSE base:\", rmse_2, \"MAPE base:\", mape_2)\n",
    "    \n",
    "    result['node'].append(node)\n",
    "    result['RMSE_1'].append(rmse_1)\n",
    "    result['MAPE_1'].append(mape_1)\n",
    "    result['RMSE_2'].append(rmse_2)\n",
    "    result['MAPE_2'].append(mape_2)\n",
    "    # interim results\n",
    "    if (rmse_1 > rmse_2):\n",
    "        balance +=1\n",
    "    else: balance-=1\n",
    "        \n",
    "    k-=1   \n",
    "    print(\"Npde:\",str(node) + \" --> k:\"+ str(k) + \" --> Success:\"+str(balance)+\"   \", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_data_XGB_1_neighb.pkl', 'wb') as f:\n",
    "    pickle.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(result)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Median\n",
    "RMSE_1 (w/o GPGN) : RMSE_2 (w/ GPGN)\n",
    "1:\n",
    "3: (135.09, 134.77)\n",
    "5: (135.09, 135.19)\n",
    "10: (135.09, 135.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135.09, 135.49)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['RMSE_1'].median(), df['RMSE_2'].median()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
